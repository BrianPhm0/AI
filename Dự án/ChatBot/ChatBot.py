import os
import google.generativeai as genai
from fastapi import FastAPI, Query, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
import pandas as pd
from dotenv import load_dotenv

# Load API Key t·ª´ .env
load_dotenv()
api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    raise ValueError("API key is missing! Please check your .env file.")

genai.configure(api_key=api_key)

# C·∫•u h√¨nh chatbot
generation_config = {
    "temperature": 0.7,
    "top_p": 0.9,
    "top_k": 40,
    "max_output_tokens": 1024,
    "response_mime_type": "text/plain",
}

model = genai.GenerativeModel(
    model_name="gemini-2.0-flash",
    generation_config=generation_config,
)

# Kh·ªüi t·∫°o FastAPI
app = FastAPI()

# C·∫•u h√¨nh CORS ƒë·ªÉ cho ph√©p frontend g·ªçi API
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Thay ƒë·ªïi th√†nh domain c·ª• th·ªÉ n·∫øu deploy
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

app.mount("/static", StaticFiles(directory="static"), name="static")

@app.get("/")
def serve_frontend():
    """Tr·∫£ v·ªÅ trang index.html"""
    return FileResponse("static/index.html")

# ƒê·ªçc d·ªØ li·ªáu t·ª´ file CSV
FILE_PATH = "restaurants.csv"
try:
    df = pd.read_csv(FILE_PATH)
    # Ch·ªâ l·∫•y c√°c c·ªôt c·∫ßn thi·∫øt v√† ƒë·ªïi t√™n n·∫øu c·∫ßn
    df = df[['name','address', 'cuisines', 'avgRating', 'priceRange', 'timeOpen']].dropna()

except FileNotFoundError:
    raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu: {FILE_PATH}")
except KeyError as e:
    raise KeyError(f"C√°c c·ªôt b·ªã thi·∫øu trong CSV: {e}")

@app.get("/chatbot")
def chatbot(query: str = Query(..., description="C√¢u h·ªèi v·ªÅ nh√† h√†ng")):
    """Chatbot t∆∞ v·∫•n nh√† h√†ng"""
    if not query:
        raise HTTPException(status_code=400, detail="C√¢u h·ªèi kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng.")
    
    # T·∫°o danh s√°ch nh√† h√†ng d·∫°ng Markdown
    restaurant_list = "\n".join(
    [
        f"<strong>{row['name']}</strong>\n"
        f"üè† ƒê·ªãa ch·ªâ: {row['address']}\n"
        f"üçΩÔ∏è ·∫®m th·ª±c: {row['cuisines']}\n"
        f"‚≠ê ƒê√°nh gi√°: {row['avgRating']}/5\n"
        f"üí∞ M·ª©c gi√°: {row['priceRange']}\n"
        f"üïí Gi·ªù m·ªü c·ª≠a: {row['timeOpen']}\n"
        for _, row in df.iterrows()
    ]
)

    
    # T·∫°o l·ªùi nh·∫Øc cho chatbot
    prompt = f"""
    B·∫°n l√† m·ªôt chatbot t∆∞ v·∫•n nh√† h√†ng cho ng∆∞·ªùi d√πng tr√™n website 
    Ng∆∞·ªùi d√πng h·ªèi: '{query}'
    
    H√£y tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng m·ªôt c√°ch r√µ r√†ng v√† d·ªÖ hi·ªÉu.
    v·ªõi m·ªói qu√°n ƒÉn, h√£y chia th√¥ng tin ra t·ª´ng d√≤ng.
    m·ªói qu√°n ƒÉn s·∫Ω ƒë∆∞·ª£c ph√¢n c√°ch b·∫±ng d·∫•u xu·ªëng d√≤ng. 
    H√£y l·ª±a ch·ªçn nh·ªØng nh√† h√†ng ph√π h·ª£p nh·∫•t v·ªõi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng.
    N·∫øu kh√¥ng t√¨m th·∫•y nh√† h√†ng ph√π h·ª£p, h√£y ƒë∆∞a ra nh·ªØng g·ª£i √Ω ·∫©m th·ª±c kh√°c.
    ƒê·ªãnh d·∫°ng c√¢u tr·∫£ l·ªùi c·ªßa b·∫°n theo Markdown ƒë·ªÉ d·ªÖ ƒë·ªçc.

    D∆∞·ªõi ƒë√¢y l√† c√°c nh√† h√†ng ph√π h·ª£p v·ªõi y√™u c·∫ßu c·ªßa b·∫°n
    {restaurant_list}
    N·∫øu kh√¥ng t√¨m th·∫•y nh√† h√†ng ph√π h·ª£p, h√£y ƒë∆∞a ra l·ªùi g·ª£i √Ω h·ª£p l√Ω.
    """


    chat_session = model.start_chat(history=[])
    response = chat_session.send_message(prompt)
    
    return {"query": query, "response": response.text}

# Ch·∫°y FastAPI tr√™n VS Code
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="127.0.0.1", port=8000, reload=True)
