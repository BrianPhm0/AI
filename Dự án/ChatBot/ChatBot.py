import os
import google.generativeai as genai
from fastapi import FastAPI, Query, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
import pandas as pd
from dotenv import load_dotenv

# Load API Key t·ª´ .env
load_dotenv()
api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    raise ValueError("API key is missing! Please check your .env file.")

genai.configure(api_key=api_key)

# C·∫•u h√¨nh chatbot
generation_config = {
    "temperature": 0.7,
    "top_p": 0.9,
    "top_k": 40,
    "max_output_tokens": 1024,
    "response_mime_type": "text/plain",
}

model = genai.GenerativeModel(
    model_name="gemini-2.0-flash",
    generation_config=generation_config,
)

# Kh·ªüi t·∫°o FastAPI
app = FastAPI()

# C·∫•u h√¨nh CORS ƒë·ªÉ cho ph√©p frontend g·ªçi API
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Thay ƒë·ªïi th√†nh domain c·ª• th·ªÉ n·∫øu deploy
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

app.mount("/static", StaticFiles(directory="static"), name="static")

@app.get("/")
def serve_frontend():
    """Tr·∫£ v·ªÅ trang index.html"""
    return FileResponse("static/index.html")

# ƒê·ªçc d·ªØ li·ªáu t·ª´ file CSV
FILE_PATH = "sorted_restaurants.csv"
try:
    df = pd.read_csv(FILE_PATH)
    # Ch·ªâ l·∫•y c√°c c·ªôt c·∫ßn thi·∫øt v√† ƒë·ªïi t√™n n·∫øu c·∫ßn
    df = df[['name','address', 'cuisines', 'Final_Score_Normalized', 'priceRange', 'timeOpen']].dropna()

except FileNotFoundError:
    raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu: {FILE_PATH}")
except KeyError as e:
    raise KeyError(f"C√°c c·ªôt b·ªã thi·∫øu trong CSV: {e}")

@app.get("/chatbot")
def chatbot(query: str = Query(..., description="C√¢u h·ªèi v·ªÅ nh√† h√†ng ho·∫∑c ·∫©m th·ª±c")):
    """Chatbot t∆∞ v·∫•n nh√† h√†ng v√† ƒë∆∞a ra g·ª£i √Ω kh√°c n·∫øu kh√¥ng ph√π h·ª£p."""
    if not query:
        raise HTTPException(status_code=400, detail="C√¢u h·ªèi kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng.")

    # L·ªçc c√°c nh√† h√†ng c√≥ th√¥ng tin ƒë·∫ßy ƒë·ªß
    filtered_df = df.dropna(subset=['name', 'address', 'cuisines', 'Final_Score_Normalized', 'priceRange', 'timeOpen'])

    # T·∫°o danh s√°ch nh√† h√†ng d·∫°ng Markdown
    restaurant_list = "\n\n".join(
        [
            f"<strong>{row['name']}</strong>\n"
            f"üè† ƒê·ªãa ch·ªâ: {row['address']}\n"
            f"üçΩÔ∏è ·∫®m th·ª±c: {row['cuisines']}\n"
            f"‚≠ê ƒê√°nh gi√°: {row['Final_Score_Normalized']}/10\n"
            f"üí∞ M·ª©c gi√°: {row['priceRange']}\n"
            f"üïí Gi·ªù m·ªü c·ª≠a: {row['timeOpen']}\n"
            for _, row in filtered_df.iterrows()
        ]
    )

    # T·∫°o l·ªùi nh·∫Øc cho chatbot
    prompt = f"""
    B·∫°n l√† m·ªôt chatbot t∆∞ v·∫•n nh√† h√†ng cho ng∆∞·ªùi d√πng tr√™n website.
    Ng∆∞·ªùi d√πng h·ªèi: '{query}'
    
    H√£y tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng m·ªôt c√°ch r√µ r√†ng v√† d·ªÖ hi·ªÉu.
    N·∫øu kh√¥ng t√¨m th·∫•y nh√† h√†ng ph√π h·ª£p, h√£y ƒë∆∞a ra c√°c g·ª£i √Ω v·ªÅ m√≥n ƒÉn ho·∫∑c ho·∫°t ƒë·ªông li√™n quan ƒë·∫øn ·∫©m th·ª±c.

    D∆∞·ªõi ƒë√¢y l√† danh s√°ch nh√† h√†ng hi·ªán c√≥:
    {restaurant_list}

    N·∫øu kh√¥ng t√¨m th·∫•y nh√† h√†ng ph√π h·ª£p, h√£y ƒë·ªÅ xu·∫•t c√°c √Ω t∆∞·ªüng ho·∫∑c m√≥n ƒÉn m√† ng∆∞·ªùi d√πng c√≥ th·ªÉ th√≠ch, d·ª±a tr√™n c√¢u h·ªèi c·ªßa h·ªç.
    ƒê·ªãnh d·∫°ng c√¢u tr·∫£ l·ªùi c·ªßa b·∫°n theo Markdown ƒë·ªÉ d·ªÖ ƒë·ªçc.
    """

    chat_session = model.start_chat(history=[])
    response = chat_session.send_message(prompt)
    
    return {"query": query, "response": response.text}


# Ch·∫°y FastAPI tr√™n VS Code
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="127.0.0.1", port=8000, reload=True)